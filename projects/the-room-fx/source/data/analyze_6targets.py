#!/usr/bin/env python3
"""
THE Room FX - 6ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
3å±¤Ã—2ãƒãƒ¼ã‚±ãƒƒãƒˆ = 6ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®å„ªå…ˆé †ä½ã¨ã‚¤ãƒ³ã‚µã‚¤ãƒˆã‚’åˆ†æ
"""

import pandas as pd
import json
from pathlib import Path
from collections import Counter
import re

# ãƒ‘ã‚¹è¨­å®š
BASE_DIR = Path(__file__).parent
PROCESSED_DIR = BASE_DIR / "processed"
ANALYSIS_DIR = BASE_DIR / "analysis"

# å…¥åŠ›ãƒ•ã‚¡ã‚¤ãƒ«
INPUT_FILE = PROCESSED_DIR / "clean.csv"

# Z/Yä¸–ä»£åˆ¤å®šã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
ZY_KEYWORDS = [
    "gen z", "genz", "millennial", "student", "college", "university",
    "grad", "young", "20s", "30s", "youth", "teenager", "teen",
    "zoomer", "generation", "undergrad", "freshman", "sophomore",
    "junior", "senior", "alumni"
]

# è¨ªæ—¥æ¤œè¨å±¤ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆJapan Interestæ‹¡å¼µï¼‰
JAPAN_KEYWORDS = [
    "japan", "japanese", "tokyo", "osaka", "kyoto", "anime", "manga",
    "æ—¥æœ¬", "æ±äº¬", "visit japan", "japan trip", "japan travel",
    "nihon", "nippon", "sushi", "ramen", "samurai", "geisha", "cherry blossom",
    "sakura", "shinkansen", "onsen", "kimono", "shibuya", "akihabara"
]

# BCæ¸¡èˆªå±¤ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
BC_KEYWORDS = [
    "business class", "first class", "premium cabin", "lie flat",
    "business travel", "frequent flyer", "status", "elite", "upgrade",
    "lounge access", "priority boarding", "premium economy"
]

# ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå›½
NA_COUNTRIES = ["US", "CA"]  # åŒ—ç±³
EU_COUNTRIES = ["UK", "DE", "FR", "IT"]  # æ¬§å·


def load_data():
    """ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã‚€"""
    print("Loading data...")
    df = pd.read_csv(INPUT_FILE, encoding='utf-8')
    print(f"Loaded {len(df)} rows")
    return df


def classify_generation(text):
    """Z/Yä¸–ä»£ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    if pd.isna(text):
        return False
    text_lower = str(text).lower()
    for kw in ZY_KEYWORDS:
        if kw in text_lower:
            return True
    return False


def classify_japan_interest(row):
    """è¨ªæ—¥æ¤œè¨å±¤ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã¾ãŸã¯æŠ•ç¨¿å†…å®¹ã‚’ãƒã‚§ãƒƒã‚¯
    profile = str(row.get('author_description', '')).lower() if pd.notna(row.get('author_description')) else ''
    content = str(row.get('content', '')).lower() if pd.notna(row.get('content')) else ''
    combined = profile + ' ' + content

    for kw in JAPAN_KEYWORDS:
        if kw in combined:
            return True
    return False


def classify_bc_traveler(row):
    """BCæ¸¡èˆªå±¤ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    # ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã¾ãŸã¯æŠ•ç¨¿å†…å®¹ã‚’ãƒã‚§ãƒƒã‚¯
    profile = str(row.get('author_description', '')).lower() if pd.notna(row.get('author_description')) else ''
    content = str(row.get('content', '')).lower() if pd.notna(row.get('content')) else ''
    combined = profile + ' ' + content

    for kw in BC_KEYWORDS:
        if kw in combined:
            return True
    return False


def get_market(country):
    """ãƒãƒ¼ã‚±ãƒƒãƒˆã‚’åˆ¤å®š"""
    if country in NA_COUNTRIES:
        return "NA"
    elif country in EU_COUNTRIES:
        return "EU"
    return None


def analyze_targets(df):
    """6ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’åˆ†æ"""
    print("\nAnalyzing 6 targets...")

    # å±¤ã®åˆ¤å®š
    df['is_zy_gen'] = df['author_description'].apply(classify_generation)
    df['is_japan_interest'] = df.apply(classify_japan_interest, axis=1)
    df['is_bc_traveler'] = df.apply(classify_bc_traveler, axis=1)

    # ãƒãƒ¼ã‚±ãƒƒãƒˆã®åˆ¤å®š
    df['market'] = df['target_country'].apply(get_market)

    # ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåœ°åŸŸã®ã¿ãƒ•ã‚£ãƒ«ã‚¿
    target_df = df[df['market'].notna()].copy()
    print(f"Target region data: {len(target_df)} rows")

    # 6ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®çµæœæ ¼ç´
    results = []

    # å„ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã‚’åˆ†æ
    targets = [
        ("ZY_NA", "Z/Yä¸–ä»£ Ã— åŒ—ç±³", "is_zy_gen", "NA"),
        ("ZY_EU", "Z/Yä¸–ä»£ Ã— æ¬§å·", "is_zy_gen", "EU"),
        ("JP_NA", "è¨ªæ—¥æ¤œè¨å±¤ Ã— åŒ—ç±³", "is_japan_interest", "NA"),
        ("JP_EU", "è¨ªæ—¥æ¤œè¨å±¤ Ã— æ¬§å·", "is_japan_interest", "EU"),
        ("BC_NA", "BCæ¸¡èˆªå±¤ Ã— åŒ—ç±³", "is_bc_traveler", "NA"),
        ("BC_EU", "BCæ¸¡èˆªå±¤ Ã— æ¬§å·", "is_bc_traveler", "EU"),
    ]

    for code, name, layer_col, market in targets:
        # ãƒ•ã‚£ãƒ«ã‚¿
        subset = target_df[(target_df[layer_col] == True) & (target_df['market'] == market)]

        if len(subset) == 0:
            results.append({
                'code': code,
                'name': name,
                'post_count': 0,
                'unique_authors': 0,
                'avg_followers': 0,
                'total_impressions': 0,
                'total_engagement': 0,
                'avg_sentiment': 0,
                'top_topic': '-',
                'top_airline': '-'
            })
            continue

        # é›†è¨ˆ
        post_count = len(subset)
        unique_authors = subset['author_name'].nunique()
        avg_followers = subset['author_followers'].mean()
        total_impressions = subset['impressions'].sum()
        total_engagement = subset['engagement'].sum()
        avg_sentiment = subset['sentiment'].mean()

        # ãƒˆãƒƒãƒ—ãƒˆãƒ”ãƒƒã‚¯
        all_topics = []
        for topics_str in subset['topics']:
            if pd.notna(topics_str):
                try:
                    topics_list = json.loads(topics_str) if isinstance(topics_str, str) else topics_str
                    all_topics.extend(topics_list)
                except:
                    pass
        top_topic = Counter(all_topics).most_common(1)[0][0] if all_topics else '-'

        # ãƒˆãƒƒãƒ—èˆªç©ºä¼šç¤¾
        airline_counts = subset['airline'].value_counts()
        top_airline = airline_counts.index[0] if len(airline_counts) > 0 else '-'

        results.append({
            'code': code,
            'name': name,
            'post_count': post_count,
            'unique_authors': unique_authors,
            'avg_followers': round(avg_followers, 0),
            'total_impressions': total_impressions,
            'total_engagement': total_engagement,
            'avg_sentiment': round(avg_sentiment, 2),
            'top_topic': top_topic,
            'top_airline': top_airline
        })

    return pd.DataFrame(results), df


def calculate_priority_score(row):
    """å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ã‚’è¨ˆç®—"""
    # ãƒœãƒªãƒ¥ãƒ¼ãƒ ï¼ˆæ­£è¦åŒ–ï¼‰
    volume_score = min(row['post_count'] / 100, 1) * 30

    # å½±éŸ¿åŠ›ï¼ˆæ­£è¦åŒ–ï¼‰
    impression_score = min(row['total_impressions'] / 1000000, 1) * 30

    # ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆï¼ˆæ­£è¦åŒ–ï¼‰
    engagement_score = min(row['total_engagement'] / 10000, 1) * 20

    # ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆï¼ˆ-5ã€œ+5ã‚’0ã€œ1ã«æ­£è¦åŒ–ã€ãƒ—ãƒ©ã‚¹ã»ã©é«˜ã„ï¼‰
    sentiment_score = ((row['avg_sentiment'] + 5) / 10) * 20

    return round(volume_score + impression_score + engagement_score + sentiment_score, 1)


def create_personas():
    """6ã‚¿ãƒ¼ã‚²ãƒƒãƒˆã®ãƒšãƒ«ã‚½ãƒŠã‚’ä½œæˆ"""
    personas = {
        "ZY_NA": {
            "name": "Alex (ã‚¢ãƒ¬ãƒƒã‚¯ã‚¹)",
            "age": "28æ­³",
            "occupation": "ãƒ†ãƒƒã‚¯ä¼æ¥­ã®ãƒ—ãƒ­ãƒ€ã‚¯ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ï¼ˆã‚µãƒ³ãƒ•ãƒ©ãƒ³ã‚·ã‚¹ã‚³ï¼‰",
            "profile": "ã‚¹ã‚¿ãƒ¼ãƒˆã‚¢ãƒƒãƒ—ã§åƒããƒŸãƒ¬ãƒ‹ã‚¢ãƒ«ä¸–ä»£ã€‚å¹´å$150Kã€‚æ—…è¡Œå¥½ãã§Instagramã§ãƒ©ã‚¤ãƒ•ã‚¹ã‚¿ã‚¤ãƒ«ã‚’ç™ºä¿¡ã€‚ãƒã‚¤ãƒ«ãƒ»ãƒã‚¤ãƒ³ãƒˆæ´»ç”¨ã«è©³ã—ã„ã€‚",
            "interests": "ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼ã€ãƒˆãƒ©ãƒ™ãƒ«ãƒãƒƒã‚¯ã€ã‚°ãƒ«ãƒ¡ã€ãƒ•ã‚£ãƒƒãƒˆãƒã‚¹",
            "bc_motivation": "é•·è·é›¢ãƒ•ãƒ©ã‚¤ãƒˆã§ã®å¿«é©æ€§ã€åˆ°ç€å¾Œã™ãã«ä»•äº‹ã§ãã‚‹çŠ¶æ…‹ã§ã„ãŸã„",
            "pain_points": "American Airlinesã®ã‚µãƒ¼ãƒ“ã‚¹å“è³ªã«ä¸æº€ã€å¤ã„æ©ŸæãŒå¤šã„",
            "appeal": "æœ€æ–°ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼æ­è¼‰ã®ã‚­ãƒ£ãƒ“ãƒ³ã€WiFiã€ã‚¢ãƒ—ãƒªé€£æºã€æ—¥æœ¬ã®å…ˆé€²æ€§"
        },
        "ZY_EU": {
            "name": "Emma (ã‚¨ãƒ)",
            "age": "32æ­³",
            "occupation": "é‡‘èæ©Ÿé–¢ã®ã‚³ãƒ³ã‚µãƒ«ã‚¿ãƒ³ãƒˆï¼ˆãƒ­ãƒ³ãƒ‰ãƒ³ï¼‰",
            "profile": "ãƒ¨ãƒ¼ãƒ­ãƒƒãƒ‘å„åœ°ã¸ã®å‡ºå¼µãŒå¤šã„Yä¸–ä»£ã€‚é€±æœ«ã¯æ—…è¡Œã‚’æ¥½ã—ã‚€ã€‚ã‚µã‚¹ãƒ†ãƒŠãƒ“ãƒªãƒ†ã‚£ã«é–¢å¿ƒã€‚",
            "interests": "ã‚µã‚¹ãƒ†ãƒŠãƒ“ãƒªãƒ†ã‚£ã€ã‚¦ã‚§ãƒ«ãƒã‚¹ã€ã‚¢ãƒ¼ãƒˆã€ãƒ¯ã‚¤ãƒ³",
            "bc_motivation": "å‡ºå¼µå¾Œã®ç–²åŠ´å›å¾©ã€ãƒ—ãƒ©ã‚¤ãƒ™ãƒ¼ãƒˆãªç©ºé–“ã§ä»•äº‹",
            "pain_points": "British Airwaysã®è€æœ½åŒ–ã€ã‚µãƒ¼ãƒ“ã‚¹ã®è³ªã®ã°ã‚‰ã¤ã",
            "appeal": "æ—¥æœ¬å¼ãŠã‚‚ã¦ãªã—ã€é™ã‹ã§è½ã¡ç€ã„ãŸç©ºé–“ã€è³ªã®é«˜ã„æ©Ÿå†…é£Ÿ"
        },
        "JP_NA": {
            "name": "Michael (ãƒã‚¤ã‚±ãƒ«)",
            "age": "35æ­³",
            "occupation": "ITä¼æ¥­ã®ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ï¼ˆãƒ‹ãƒ¥ãƒ¼ãƒ¨ãƒ¼ã‚¯ï¼‰",
            "profile": "æ—¥æœ¬æ–‡åŒ–ã«æ·±ã„é–¢å¿ƒã‚’æŒã¤ã€‚ã‚¢ãƒ‹ãƒ¡ãƒ»ã‚²ãƒ¼ãƒ ãŒãã£ã‹ã‘ã§æ—¥æœ¬ã«èˆˆå‘³ã€‚å¹´1å›ã¯æ—¥æœ¬æ—…è¡Œã€‚æ—¥æœ¬èªå­¦ç¿’ä¸­ã€‚",
            "interests": "ã‚¢ãƒ‹ãƒ¡ã€ã‚²ãƒ¼ãƒ ã€æ—¥æœ¬é£Ÿã€æ¸©æ³‰ã€ãƒ†ã‚¯ãƒãƒ­ã‚¸ãƒ¼",
            "bc_motivation": "æ—¥æœ¬ã¸ã®é•·æ™‚é–“ãƒ•ãƒ©ã‚¤ãƒˆã‚’å¿«é©ã«ã€åˆ°ç€å¾Œã™ãã«è¦³å…‰ã‚’æ¥½ã—ã¿ãŸã„",
            "pain_points": "æ—¥æœ¬è¡Œãç›´è¡Œä¾¿ã®é¸æŠè‚¢ãŒå°‘ãªã„ã€æ©Ÿå†…ã§ã®æ—¥æœ¬ä½“é¨“ãŒãªã„",
            "appeal": "æ—¥æœ¬ã‚’æ„Ÿã˜ã‚‰ã‚Œã‚‹æ©Ÿå†…ä½“é¨“ã€ANAã®æ—¥æœ¬å“è³ªã€æˆç”°/ç¾½ç”°ã¸ã®ç›´è¡Œä¾¿"
        },
        "JP_EU": {
            "name": "Sophie (ã‚½ãƒ•ã‚£ãƒ¼)",
            "age": "29æ­³",
            "occupation": "ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³æ¥­ç•Œã®ãƒã‚¤ãƒ¤ãƒ¼ï¼ˆãƒ‘ãƒªï¼‰",
            "profile": "æ—¥æœ¬ã®ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ãƒ»ãƒ‡ã‚¶ã‚¤ãƒ³ã«é–¢å¿ƒã€‚å¹´2å›ã®æ±äº¬å‡ºå¼µã€‚æ—¥æœ¬ã®ç¾æ„è­˜ã«å…±æ„Ÿã€‚",
            "interests": "ãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ã€ãƒ‡ã‚¶ã‚¤ãƒ³ã€æ—¥æœ¬å»ºç¯‰ã€èŒ¶é“ã€äº¬éƒ½",
            "bc_motivation": "é•·è·é›¢ãƒ•ãƒ©ã‚¤ãƒˆã§ã®ç¾å®¹ãƒ»ã‚¹ã‚­ãƒ³ã‚±ã‚¢ã€åˆ°ç€æ™‚ã®ã‚³ãƒ³ãƒ‡ã‚£ã‚·ãƒ§ãƒ³",
            "pain_points": "æ¬§å·ã‹ã‚‰æ—¥æœ¬ã¸ã®ç›´è¡Œä¾¿ã®ä¹—ã‚Šç¶™ãã€æ©Ÿå†…ã®ä¹¾ç‡¥",
            "appeal": "ANAã®ç¾æ„è­˜ã€ã‚¹ã‚­ãƒ³ã‚±ã‚¢ã‚¢ãƒ¡ãƒ‹ãƒ†ã‚£ã€æ—¥æœ¬ã®ã€ŒãŠã‚‚ã¦ãªã—ã€"
        },
        "BC_NA": {
            "name": "David (ãƒ‡ã‚¤ãƒ“ãƒƒãƒ‰)",
            "age": "45æ­³",
            "occupation": "è£½é€ æ¥­ã®å‰¯ç¤¾é•·ï¼ˆã‚·ã‚«ã‚´ï¼‰",
            "profile": "æœˆ2å›ä»¥ä¸Šã®æµ·å¤–å‡ºå¼µã€‚ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ä¼šå“¡ã€‚åŠ¹ç‡ã¨å¿«é©æ€§ã‚’é‡è¦–ã€‚å®¶æ—ã¨ã®æ™‚é–“ã‚’å¤§åˆ‡ã«ã—ãŸã„ã€‚",
            "interests": "ã‚´ãƒ«ãƒ•ã€ãƒ“ã‚¸ãƒã‚¹ã€æŠ•è³‡ã€å®¶æ—",
            "bc_motivation": "ç§»å‹•æ™‚é–“ã®æœ‰åŠ¹æ´»ç”¨ã€ç¡çœ ã®è³ªã€åˆ°ç€å¾Œã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹",
            "pain_points": "American Airlinesã®é…å»¶ãƒ»ã‚µãƒ¼ãƒ“ã‚¹ä½ä¸‹ã€ä¾¡å€¤ã«è¦‹åˆã‚ãªã„",
            "appeal": "å®šæ™‚é‹èˆªç‡ã€ãƒ“ã‚¸ãƒã‚¹ã«é›†ä¸­ã§ãã‚‹ç’°å¢ƒã€ç–²ã‚Œãªã„åº§å¸­"
        },
        "BC_EU": {
            "name": "Thomas (ãƒˆãƒ¼ãƒã‚¹)",
            "age": "42æ­³",
            "occupation": "è‡ªå‹•è»Šãƒ¡ãƒ¼ã‚«ãƒ¼ã®ã‚¨ã‚°ã‚¼ã‚¯ãƒ†ã‚£ãƒ–ï¼ˆãƒ•ãƒ©ãƒ³ã‚¯ãƒ•ãƒ«ãƒˆï¼‰",
            "profile": "ã‚¢ã‚¸ã‚¢ï¼ˆç‰¹ã«æ—¥æœ¬ï¼‰ã¨ã®å–å¼•ãŒå¤šã„ã€‚å“è³ªã¨åŠ¹ç‡ã‚’é‡è¦–ã€‚Lufthansaã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ä¼šå“¡ã ãŒä¸æº€ã‚‚ã€‚",
            "interests": "è‡ªå‹•è»Šã€å“è³ªç®¡ç†ã€æ—¥æœ¬æ–‡åŒ–ã€ãƒ“ã‚¸ãƒã‚¹",
            "bc_motivation": "æ—¥æœ¬å‡ºå¼µæ™‚ã®å¿«é©æ€§ã€æ™‚å·®ãƒœã‚±å¯¾ç­–ã€æ©Ÿå†…ã§ã®ä»•äº‹",
            "pain_points": "Lufthansaã®æœ€è¿‘ã®ã‚µãƒ¼ãƒ“ã‚¹ä½ä¸‹ã€ã‚¹ãƒˆãƒ©ã‚¤ã‚­",
            "appeal": "æ—¥æœ¬å“è³ªã®ã‚µãƒ¼ãƒ“ã‚¹ã€é™ç²›æ€§ã€æ™‚å·®ãƒœã‚±å¯¾ç­–ã®ã‚µãƒãƒ¼ãƒˆ"
        }
    }
    return personas


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 60)
    print("THE Room FX - 6 Target Analysis")
    print("=" * 60)

    # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
    df = load_data()

    # 6ã‚¿ãƒ¼ã‚²ãƒƒãƒˆåˆ†æ
    results_df, enriched_df = analyze_targets(df)

    # å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢è¨ˆç®—
    results_df['priority_score'] = results_df.apply(calculate_priority_score, axis=1)

    # å„ªå…ˆåº¦é †ã«ã‚½ãƒ¼ãƒˆ
    results_df = results_df.sort_values('priority_score', ascending=False).reset_index(drop=True)
    results_df['rank'] = range(1, len(results_df) + 1)

    # ä¿å­˜
    results_df.to_csv(ANALYSIS_DIR / "6target_analysis.csv", index=False, encoding='utf-8')

    print("\n" + "=" * 60)
    print("6 Target Analysis Results")
    print("=" * 60)

    # çµæœè¡¨ç¤º
    print("\nğŸ“Š 6ã‚¿ãƒ¼ã‚²ãƒƒãƒˆå„ªå…ˆé †ä½:")
    print("-" * 80)
    for _, row in results_df.iterrows():
        print(f"#{row['rank']} {row['name']}")
        print(f"   æŠ•ç¨¿æ•°: {row['post_count']}, è‘—è€…æ•°: {row['unique_authors']}, "
              f"ã‚¤ãƒ³ãƒ—ãƒ¬: {row['total_impressions']:,}, ã‚»ãƒ³ãƒ: {row['avg_sentiment']}")
        print(f"   ã‚¹ã‚³ã‚¢: {row['priority_score']}, ãƒˆãƒƒãƒ—è©±é¡Œ: {row['top_topic']}, "
              f"ãƒˆãƒƒãƒ—èˆªç©º: {row['top_airline']}")
        print()

    # ãƒšãƒ«ã‚½ãƒŠä½œæˆ
    personas = create_personas()

    # ãƒšãƒ«ã‚½ãƒŠãƒ¬ãƒãƒ¼ãƒˆä¿å­˜
    persona_report = "# THE Room FX - 6ã‚¿ãƒ¼ã‚²ãƒƒãƒˆ ãƒšãƒ«ã‚½ãƒŠ\n\n"

    for _, row in results_df.iterrows():
        code = row['code']
        persona = personas.get(code, {})

        persona_report += f"## #{row['rank']} {row['name']}\n\n"
        persona_report += f"### ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼\n\n"
        persona_report += f"| æŒ‡æ¨™ | å€¤ |\n"
        persona_report += f"|------|-----|\n"
        persona_report += f"| æŠ•ç¨¿æ•° | {row['post_count']} |\n"
        persona_report += f"| ãƒ¦ãƒ‹ãƒ¼ã‚¯è‘—è€…æ•° | {row['unique_authors']} |\n"
        persona_report += f"| å¹³å‡ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼ | {row['avg_followers']:,.0f} |\n"
        persona_report += f"| ç·ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ | {row['total_impressions']:,} |\n"
        persona_report += f"| ç·ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆ | {row['total_engagement']:,} |\n"
        persona_report += f"| å¹³å‡ã‚»ãƒ³ãƒãƒ¡ãƒ³ãƒˆ | {row['avg_sentiment']} |\n"
        persona_report += f"| ãƒˆãƒƒãƒ—ãƒˆãƒ”ãƒƒã‚¯ | {row['top_topic']} |\n"
        persona_report += f"| ãƒˆãƒƒãƒ—èˆªç©ºä¼šç¤¾ | {row['top_airline']} |\n"
        persona_report += f"| å„ªå…ˆåº¦ã‚¹ã‚³ã‚¢ | {row['priority_score']} |\n\n"

        if persona:
            persona_report += f"### ãƒšãƒ«ã‚½ãƒŠ: {persona['name']}\n\n"
            persona_report += f"| é …ç›® | å†…å®¹ |\n"
            persona_report += f"|------|------|\n"
            persona_report += f"| å¹´é½¢ | {persona['age']} |\n"
            persona_report += f"| è·æ¥­ | {persona['occupation']} |\n"
            persona_report += f"| ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ« | {persona['profile']} |\n"
            persona_report += f"| é–¢å¿ƒäº‹ | {persona['interests']} |\n"
            persona_report += f"| BCåˆ©ç”¨å‹•æ©Ÿ | {persona['bc_motivation']} |\n"
            persona_report += f"| ãƒšã‚¤ãƒ³ãƒã‚¤ãƒ³ãƒˆ | {persona['pain_points']} |\n"
            persona_report += f"| **è¨´æ±‚ãƒã‚¤ãƒ³ãƒˆ** | **{persona['appeal']}** |\n\n"

        persona_report += "---\n\n"

    with open(ANALYSIS_DIR / "6target_personas.md", 'w', encoding='utf-8') as f:
        f.write(persona_report)

    print(f"\nSaved: {ANALYSIS_DIR / '6target_analysis.csv'}")
    print(f"Saved: {ANALYSIS_DIR / '6target_personas.md'}")

    return results_df


if __name__ == "__main__":
    main()
